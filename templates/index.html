<!-- templates/index.html -->
<!DOCTYPE html>
<html>
<head>
    <title>Sign Language Translator</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.18.0"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/hand-pose-detection@0.0.7"></script>
</head>
<body>
    <video id="webcam" autoplay playsinline></video>
    <button id="capture">Capture & Translate</button>
    <div id="result"></div>

    <script>
        // Load model and hand detector
        async function setup() {
            const model = await tf.loadLayersModel('model/model.json');
            const detector = await handPoseDetection.createDetector(
                handPoseDetection.SupportedModels.MediaPipeHands
            );
            
            document.getElementById('capture').onclick = async () => {
                const video = document.getElementById('webcam');
                const hands = await detector.estimateHands(video);
                
                if (hands.length > 0) {
                    // Process hand landmarks and predict
                    const prediction = model.predict(preprocess(hands[0]));
                    const label = ['Hello', 'Yes', 'No', 'I Love You', 'Okay', 'Please', 'Thank You'][
                        prediction.argMax(1).dataSync()[0]
                    ];
                    document.getElementById('result').textContent = label;
                }
            };
            
            // Start webcam
            navigator.mediaDevices.getUserMedia({ video: true })
                .then(stream => document.getElementById('webcam').srcObject = stream);
        }
        
        setup();
    </script>
</body>
</html>
